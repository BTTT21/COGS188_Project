{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minesweeper\n",
    "\n",
    "# Names\n",
    "---\n",
    "Haoyu(Eric) Wang  \n",
    "Gexiang(Jason) Zhang  \n",
    "Bryant Zhu  \n",
    "Jiachen Xu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "---\n",
    "Our project aims to develop an advanced AI system to efficiently solve 16x16 Minesweeper by implementing Constraint Satisfaction Problem (CSP) techniques, Monte Carlo simulations, and Dynamic Programming. Unlike toy problems, Minesweeper presents a complex action space with both deterministic logic-based decisions and probabilistic uncertainty, making it a compelling testbed for AI methods.\n",
    "\n",
    "Our AI system will be evaluated using multiple performance metrics, including completion rate, accuracy, and computational efficiency, to identify the most effective combination of techniques. We will also explore hyperparameter tuning to optimize model performance. The results will provide insights into the strengths and limitations of each approach, contributing to a deeper understanding of AI-driven problem-solving in Minesweeper.\n",
    "\n",
    "Major results:..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "---\n",
    "Minesweeper is a classic puzzle widely studied in artificial intelligence (AI) due to its mix of deterministic logic and probabilistic guessing. It is an NP-complete problem<a id=\"cite_ref-1\" href=\"#cite_note-1\"><sup>[1]</sup></a>which means no known polynomial-time algorithm can solve all instances efficiently. This computational complexity has made Minesweeper a valuable testbed for diverse AI techniques, including constraint satisfaction, reinforcement learning, and probabilistic methods.\n",
    "\n",
    "In constraint satisfaction approaches<a id=\"cite_ref-2\" href=\"#cite_note-2\"><sup>[2]</sup></a>, each revealed number imposes logical constraints on hidden cells. While these methods excel at deterministic deduction, they falter when forced guesses arise. Monte Carlo simulations<a id=\"cite_ref-3\" href=\"#cite_note-3\"><sup>[3]</sup></a> address such uncertainty by sampling multiple hypothetical board configurations, though they can be computationally expensive at larger scales. Reinforcement learning<a id=\"cite_ref-4\" href=\"#cite_note-4\"><sup>[4]</sup></a> has also been explored, but its progress can be slowed by the sparse reward structure of Minesweeper.\n",
    "\n",
    "Building on these insights, our project seeks to integrate Constraint Satisfaction Problem (CSP) methods, Monte Carlo simulations, and Dynamic Programming (DP). By combining logic-based inference with probabilistic reasoning and systematic optimization, we aim to develop a robust Minesweeper-solving AI that can handle both certain and uncertain states efficiently. This hybrid approach not only advances the state of Minesweeper-solving techniques but also offers broader lessons for AI planning and decision-making under uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brief Rules:**  \n",
    "In Minesweeper, you are presented with a grid where certain cells hide mines. The objective is to reveal all safe cells without uncovering any mines. When a safe cell is revealed, it displays a number that indicates how many of its adjacent cells contain mines; if the number is zero, a cascade effect automatically reveals its neighboring cells. Players can also flag cells they suspect to contain mines to avoid accidental clicks.\n",
    "\n",
    "**Environment, Actions, Transition, Reward and Goal:**  \n",
    "The game is played on a 16*16 grid with a predetermined number of mines randomly placed at the start. The player interacts with the environment by choosing to reveal a cell at given coordinates or flag/unflag a cell as potentially dangerous. When a cell is revealed, if it is safe, the board updates to show the number of adjacent mines; if that number is zero, it triggers a cascade reveal of neighboring cells. However, revealing a mine immediately ends the game in a loss. The reward structure typically offers small rewards for safe moves and a significant positive reward for successfully uncovering all safe cells (winning), while revealing a mine results in a large negative reward (losing). The overall goal is to strategically reveal every safe cell without triggering any mines, leveraging logical deduction and, when necessary, probabilistic reasoning.\n",
    "\n",
    "**Potential Challenges:**  \n",
    "The main challenges include dealing with partial observability, as the true locations of mines remain hidden until revealed, and handling ambiguous situations that may force the player to guess. Additionally, Minesweeper is computationally complex (NP-complete), and the sparse reward structure can make it difficult for algorithmic or learning-based approaches to effectively deduce optimal moves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "---\n",
    "In this project, we will apply three distinct methods—**Dynamic Programming (DP)**, **Monte Carlo (MC) simulations**, and **Constraint Satisfaction Problem (CSP)** techniques—to solve the 16x16 Minesweeper puzzle. Each of these methods will be implemented independently, and their performances will be compared to determine which approach provides the most efficient and accurate solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Dynamic Programming (DP):**\n",
    "\n",
    "We will model the Minesweeper grid as a **Markov Decision Process (MDP)**, where the state of the game is represented by the configuration of tiles (either mines or safe spaces). The objective is to uncover safe tiles while avoiding mines, guided by the numeric clues provided on the grid.\n",
    "\n",
    "**Value Iteration:** This algorithm iteratively updates the value of each state (tile) based on its neighboring states and the rewards (whether it's a safe tile or a mine). It computes the expected value of uncovering each tile, considering both deterministic and probabilistic outcomes.  \n",
    "**Policy Iteration:** After estimating the values of states, this algorithm will derive the optimal policy—i.e., the best action (whether to uncover or skip a tile) to maximize the chances of winning.   \n",
    "\n",
    "DP is highly effective in environments where the transitions between states are known and can be modeled deterministically. By iterating over the grid, DP can ensure optimal decision-making by considering the entire game state at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Monte Carlo (MC) Simulations:**\n",
    "\n",
    "Monte Carlo simulations will be used to handle the probabilistic nature of Minesweeper. The idea is to simulate multiple random games (trajectories) and use the results to estimate the most likely safe moves. This will involve the following steps:\n",
    "\n",
    "**Random Sampling:** At each step, a random decision will be made based on the probabilities of safe tiles. This is akin to exploring various possible states the game could be in, given partial information.  \n",
    "**Exploration vs. Exploitation:** The algorithm will balance between exploring unknown tiles (exploration) and exploiting the information from already uncovered tiles (exploitation).    \n",
    "\n",
    "MC simulations are particularly useful in solving problems with uncertainty, as they approximate the solution by simulating a large number of possible scenarios. By performing many simulations, the algorithm can generate an accurate estimate of the most probable outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Constraint Satisfaction Problem (CSP):**\n",
    "\n",
    "Minesweeper can be modeled as a Constraint Satisfaction Problem (CSP), where each tile is a variable with a domain of {Mine, Safe}. The constraints come from the numerical clues on each uncovered tile, indicating the number of mines in the adjacent tiles. Our approach will be based on backtracking and forward checking to efficiently search for a solution while satisfying the constraints.\n",
    "\n",
    "**Backtracking:** This algorithm will systematically explore all possible configurations of safe and mine tiles, backtracking when a configuration violates a constraint.  \n",
    "**Forward Checking:** After each decision, forward checking will be used to prune the search space by eliminating values from the domains of adjacent variables that cannot possibly satisfy the constraints.    \n",
    "\n",
    "CSPs are a good fit for Minesweeper because the game's constraints (the numbers on the uncovered tiles) must be satisfied while assigning values (Mine or Safe) to the tiles. Backtracking and forward checking are both well-established techniques for solving CSPs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ALL THREE of the potential solutions will be tested based on the evaluation metrics below. We might also include some unit test to measure behavior or perfomance throught the developing process.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "---\n",
    "To evaluate the performance of our Minesweeper AI agents, we propose several evaluation metrics that reflect accuracy and efficiency. \n",
    "\n",
    "**Win Rate:** Win Rate = Number of Games Won / Total Games Played x 100%  \n",
    "The win rate will serve as the primary benchmark, measuring the percentage of games won out of the total games played. This metric quantifies the overall success of each AI strategy.\n",
    "\n",
    "**Efficiency:** Average Completion Time  \n",
    "To assess efficiency, we will use the average game completion time, which calculates the mean duration (in seconds) taken to finish a game, whether won or lost. \n",
    "\n",
    "**Exploration Rate:** Exploration Rate = Non-Mine Tiles Revealed / Total Non-Mine Tiles x 100%  \n",
    "The exploration rate will evaluate how thoroughly the AI reveals non-mine tiles, serving as an indicator of its exploration strategy.  \n",
    "\n",
    "Together, these quantifiable metrics will provide a comparison of the performance between the benchmark and proposed AI models, and the best performing model will be our solution model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "---\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Probably you should include a learning curve to demonstrate how much better the model gets as you increase the number of trials\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Generally reinforement learning tasks may require a huge amount of training, so extensive grid search is unlikely to be possible. However expoloring a few reasonable hyper-parameters may still be possible.  Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?  Or you compare a completely different approach/alogirhtm to the problem? Whatever, this stuff is just serving suggestions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-Mines-Game\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future work\n",
    "\n",
    "Looking at the limitations and/or the toughest parts of the problem and/or the situations where the algorithm(s) did the worst... is there something you'd like to try to make these better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethics & Privacy\n",
    "\n",
    "While our project does not involve sensitive user data, there are several ethical considerations to take into account:\n",
    "\n",
    "**Algorithmic Transparency and Explainability:**  \n",
    "AI-driven Minesweeper solvers can act as a testbed for more complex decision-making systems. Ensuring that the decision-making process remains interpretable and explainable is crucial, particularly when applying similar methodologies in real-world scenarios such as medical diagnosis or risk assessment. Black-box AI models can lead to unpredictable or untrustworthy behavior in safety-critical applications<a id=\"cite_ref-5\" href=\"#cite_note-5\"><sup>[5]</sup></a> .\n",
    "\n",
    "**Unintended Bias in AI Decision-Making:**  \n",
    "Although Minesweeper is a well-defined game with no external biases, the algorithms developed for solving it may have inherent biases due to their reliance on heuristic approximations. For instance, certain algorithms may favor safer strategies that prioritize known information over exploration, potentially leading to suboptimal long-term performance. This consideration is particularly relevant when extending these AI techniques to real-world applications such as autonomous systems or financial modeling.\n",
    "\n",
    "**Computational Resource Consumption:**  \n",
    "AI models, particularly those using Monte Carlo simulations or Reinforcement Learning, require significant computational resources for training and execution. Excessive resource consumption has environmental and ethical implications, especially given concerns over the carbon footprint of large-scale machine learning models<a id=\"cite_ref-6\" href=\"#cite_note-6\"><sup>[6]</sup></a> . To address this, our implementation will focus on optimizing computational efficiency by using targeted simulations and avoiding unnecessary computations.\n",
    "\n",
    "**Broader Ethical Implications of AI in Decision-Making:**  \n",
    "The AI methodologies applied in this project—such as CSP, Monte Carlo simulations, and RL—are widely used in fields such as finance, healthcare, and security. While our project is focused on Minesweeper, similar AI decision-making techniques could be applied in high-stakes scenarios where incorrect or biased decisions could have real-world consequences. Ensuring the ethical development of AI systems and recognizing their broader impact is a fundamental responsibility of AI researchers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "---\n",
    "\n",
    "1. <a id=\"cite_note-1\" href=\"#cite_ref-1\">Kaye, R. (2000). *Minesweeper is NP-complete*. The Mathematical Intelligencer, 22(2), 9–15.   \n",
    "\n",
    "2. <a id=\"cite_note-2\" href=\"#cite_ref-2\">Littman, M. L., Sutton, R. S., & Singh, S. (2002). *Predictive representations of state*. Advances in Neural Information Processing Systems.\n",
    "\n",
    "3. <a id=\"cite_note-3\" href=\"#cite_ref-3\">Chin, C. S., Qiu, J., & Lau, H. C. (2019). *Solving Minesweeper using Monte Carlo Tree Search*. Proceedings of the International Conference on Artificial Intelligence. \n",
    "\n",
    "4. <a id=\"cite_note-4\" href=\"#cite_ref-4\">Wu, C., & Baldi, P. (2020). *Learning to Play Minesweeper with Deep Reinforcement Learning*. arXiv preprint arXiv:2006.15485. \n",
    "\n",
    "5. <a id=\"cite_note-5\" href=\"#cite_ref-5\">Lipton, Z. C. (2018). *The Mythos of Model Interpretability*. arXiv preprint arXiv:1606.03490. \n",
    "\n",
    "6. <a id=\"cite_note-6\" href=\"#cite_ref-6\">Strubell, E., Ganesh, A., & McCallum, A. (2019). *Energy and Policy Considerations for Deep Learning in NLP*. arXiv preprint arXiv:1906.02243. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
